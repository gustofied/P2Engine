# P2Engine - Multi-Agent Orchestration Framework

<div align="center">

[![Python 3.9+](https://img.shields.io/badge/python-3.9+-blue.svg)](https://www.python.org/downloads/)
[![Poetry](https://img.shields.io/badge/dependency%20management-poetry-blueviolet)](https://python-poetry.org/)
[![Redis](https://img.shields.io/badge/cache-redis-red)](https://redis.io/)
[![Celery](https://img.shields.io/badge/task%20queue-celery-green)](https://docs.celeryproject.org/)
[![Daml](https://img.shields.io/badge/ledger-daml-blue)](https://www.digitalasset.com/developers)

**Master's Thesis Project**  
_A production-ready framework for orchestrating conversational AI agents with distributed task execution, financial ledger integration, and comprehensive evaluation capabilities._

</div>

## üåü Overview

P2Engine is a sophisticated multi-agent orchestration platform developed as a Master's thesis project. The system demonstrates advanced concepts in distributed AI systems:

- **Multi-Agent Conversations**: Agents can delegate tasks to each other, creating complex interaction hierarchies
- **Financial Ledger Integration**: Built-in Canton/Daml ledger for agent wallet management and transactions
- **Distributed Task Processing**: Celery-based task queue for scalable tool execution
- **Evaluation Framework**: Automated quality assessment with configurable judges and metrics
- **Rollout System**: A/B testing and variant comparison for agent configurations
- **Tool Ecosystem**: Extensible tool system with caching, deduplication, and post-effects

The entire system is orchestrated through a single entry point (`./scripts/run_project.sh`) that handles all the complexity of distributed system initialization.

## üèóÔ∏è Architecture

```

```

## üöÄ Quick Start

### Prerequisites

- Python 3.9+
- Redis
- Poetry (for dependency management)
- Daml SDK (optional, for ledger features)
- OpenAI API key

### Installation

```bash
# Clone the repository
git clone <repository-url>
cd p2engine

# Install dependencies
poetry install

# Set up environment variables
cp .env.example .env
# Edit .env with your configuration (see Environment Configuration below)

# Initialize Canton/Daml (optional, for ledger features)
./scripts/setup_canton.sh
```

### Environment Configuration (.env)

The `.env` file contains all critical configuration for the system. Here's a complete guide:

```bash
# Configuration file path (optional - defaults to config/config.json)
CONFIG_FILE=config/config.json

# OpenAI API Configuration (REQUIRED)
# Get your API key from: https://platform.openai.com/api-keys
OPENAI_API_KEY="sk-your-api-key-here"

# Canton/Ledger Configuration
# Set to false to run without financial ledger features (faster startup)
LEDGER_ENABLED=true

# Daml Package ID (auto-generated when building Daml project)
# This is set automatically by run_project.sh when ledger is enabled
DAML_PACKAGE_ID=auto_generated_on_build

# Logging Configuration
LOG_LEVEL=INFO              # Main application log level
WORKER_LOG_LEVEL=INFO       # Celery worker log level
LITELLM_LOG_LEVEL=error     # LLM library log level (set to debug for API traces)
LOG_TO_CONSOLE=0            # Set to 1 to see logs in console

# Redis Configuration (optional - these are the defaults)
REDIS_HOST=localhost
REDIS_PORT=6379
REDIS_DB=0

# Tool Deduplication Policy
# Options:
#   - none: No deduplication, all tool calls execute
#   - penalty: Track duplicates but allow execution
#   - strict: Block duplicate side-effect operations
DEDUP_POLICY=none

# Artifact Storage Driver
# Options:
#   - fs: Filesystem storage (default, no setup required)
#   - s3: AWS S3 storage (requires S3_BUCKET env var)
ARTIFACT_DRIVER=fs

# Development/Debugging Options
# LOG_TO_CONSOLE=1           # Show logs in terminal
# LITELLM_LOG_LEVEL=debug    # See all LLM API calls
# LEDGER_DEV_MODE=true       # Auto-set for development
```

### Running the System

The **primary way** to run P2Engine is through the orchestration script:

```bash
# This single command starts EVERYTHING:
./scripts/run_project.sh
```

#### What run_project.sh does:

1. **Environment Setup**: Loads `.env` configuration
2. **Process Cleanup**: Kills any existing P2Engine processes
3. **Redis Initialization**: Starts Redis and clears the database
4. **Canton/Ledger Setup** (if LEDGER_ENABLED=true):
   - Builds the Daml project
   - Extracts and sets DAML_PACKAGE_ID
   - Starts Canton daemon
   - Launches JSON API
   - Initializes agent wallets
5. **Celery Workers**: Starts 4 worker queues:
   - `ticks`: Main orchestration queue (16 workers)
   - `tools`: Tool execution queue (16 workers)
   - `evals`: Evaluation queue (8 workers + beat scheduler)
   - `rollouts`: Rollout execution queue (2 workers)
6. **Engine**: Starts the main runtime engine
7. **CLI**: Launches the interactive shell

The script handles all the complex orchestration and provides:

- Automatic log rotation with timestamped directories
- Process monitoring with PIDs
- Graceful shutdown on Ctrl+C
- Health checks for all services

#### Manual Component Start (Advanced)

If you need to run components separately for debugging:

```bash
# 1. Redis
redis-server

# 2. Canton (if using ledger)
./scripts/start_canton.sh

# 3. Celery workers
poetry run celery -A runtime.tasks.celery_app worker -Q ticks -n ticks@%h
poetry run celery -A runtime.tasks.celery_app worker -Q tools -n tools@%h
poetry run celery -A runtime.tasks.celery_app worker -Q evals -n evals@%h
poetry run celery -A runtime.tasks.celery_app worker -Q rollouts -n rollouts@%h

# 4. Engine
poetry run python runtime/engine.py

# 5. CLI
poetry run p2engine shell
```

## üí¨ Basic Usage

### Starting a Chat

```bash
# Start a conversation with an agent
p2engine chat with agent_alpha

# In the chat:
You> Hello! What can you do?
You> Check my balance
You> Transfer 25 to agent_beta for helping with analysis
You> What's the weather in Paris?
```

### Multi-Agent Delegation

```bash
# Agents can delegate to each other
You> Delegate to agent_helper: What's the weather in Tokyo?
You> If they did well, reward them 20 units
```

### Using the Shell

```bash
p2engine shell

# Available commands:
p2engine‚ñ∏ agent list
p2engine‚ñ∏ conversation list
p2engine‚ñ∏ ledger balance agent_alpha
p2engine‚ñ∏ rollout start config/demo_rollout.yml
```

## üí∞ Ledger Operations

P2Engine includes a full financial ledger system powered by Canton/Daml:

### Initialize Wallets

```bash
# Initialize all agent wallets with starting balance
p2engine ledger init --balance 100.0
```

### Check Balances

```bash
# Check specific agent balance
p2engine ledger balance agent_alpha

# Check system metrics
p2engine ledger metrics

# View all wallets
p2engine ledger overview
```

### Transfer Funds

```bash
# Direct transfer via CLI
p2engine ledger transfer agent_alpha agent_beta 25.0 --reason "Payment for services"

# Or through agent conversation
p2engine chat with agent_alpha
You> Transfer 50 to treasurer for management fees
```

### Transaction History

```bash
# View agent's transaction history
p2engine ledger history agent_alpha --limit 20

# Audit trail for all ledger events
p2engine ledger audit
```

## üß™ Rollout System

The rollout system enables A/B testing and evaluation of different agent configurations:

### Example Rollout Configuration

```yaml
# config/example_rollout.yml
teams:
  weather_team:
    initial_message: "What's the weather in major cities?"
    base:
      agent_id: agent_alpha
      model: openai/gpt-4o
    variants:
      - tools: ["get_weather"]
        temperature: 0.3
      - tools: ["get_weather", "delegate"]
        temperature: 0.7
    eval:
      evaluator_id: gpt4_judge
      metric: score
      rubric: |
        Score based on:
        - Accuracy of weather information (0.5)
        - Helpfulness and clarity (0.5)
```

### Running Rollouts

```bash
# Start a rollout
p2engine rollout start config/rollout_joke.yml --follow

# View results
p2engine eval top <session_id> --metric score
```

## üõ†Ô∏è Creating Custom Tools

Tools extend agent capabilities. Here's how to create one:

```python
# tools/my_custom_tool.py
from pydantic import BaseModel
from agents.decorators import function_tool

class MyToolInput(BaseModel):
    query: str
    limit: int = 10

@function_tool(
    name="search_database",
    description="Search the knowledge database",
    input_schema=MyToolInput,
    cache_ttl=300,  # Cache for 5 minutes
    side_effect_free=True,
)
def search_database(query: str, limit: int = 10) -> dict:
    # Implementation here
    results = perform_search(query, limit)
    return {
        "status": "success",
        "data": results,
        "count": len(results)
    }
```

## üéØ Advanced Features

### Branch Management

```bash
# View conversation branches
p2engine conversation branches <conversation_name>

# Rewind to a previous state
p2engine conversation rewind <conversation_name> 10 --branch

# Checkout a different branch
p2engine conversation checkout <conversation_name> <branch_id>
```

### Real-time Monitoring

```bash
# Watch conversation stack in real-time
p2engine conversation watch <conversation_name>

# Monitor artifacts
p2engine artifact show <conversation_id> --limit 50
```

### Configuration Overrides

```bash
# Change agent behavior
p2engine config set-behavior <conversation> weather_expert

# Override tools
p2engine config set-tools <conversation> get_weather,delegate,check_balance

# View current overrides
p2engine config show-overrides <conversation>
```

## üìä Evaluation System

P2Engine includes a sophisticated evaluation framework:

### Built-in Evaluators

- **gpt4_judge**: General-purpose quality evaluation
- Custom rubrics for specific use cases

### Creating Custom Evaluators

```python
from infra.evals.llm_eval import LLMEvaluator
from infra.evals.registry import evaluator

@evaluator(id="domain_expert", version="1.0")
class DomainExpertEvaluator(LLMEvaluator):
    model = "openai/gpt-4o"

    def build_messages(self, payload):
        # Custom evaluation logic
        return [...]
```

## üîß Configuration

### Main Configuration (`config/config.json`)

```json
{
  "redis": {
    "host": "localhost",
    "port": 6379,
    "db": 0
  },
  "llm": {
    "api_base": "https://api.openai.com/v1",
    "models": {
      "default_model": "openai/gpt-4o"
    }
  },
  "ledger": {
    "enabled": true,
    "json_api_url": "http://localhost:7575",
    "party_id": "p2engine::default",
    "initial_balance": 100.0
  }
}
```

### Agent Configuration (`config/agents.yml`)

```yaml
agents:
  - id: agent_alpha
    type: llm
    llm_model: "openai/gpt-4o"
    tools: ["get_weather", "delegate", "check_balance", "transfer_funds"]

  - id: treasurer
    type: llm
    llm_model: "openai/gpt-4o"
    behavior_template: "financial_expert"
    tools: ["check_balance", "transfer_funds", "transaction_history"]
```

## üß™ Testing Scenarios

### Multi-Agent Collaboration Test

```bash
p2engine chat with agent_alpha

# Test delegation chain
You> Check my balance
You> Delegate to treasurer: Please distribute 100 units equally among agent_beta, agent_helper, and child
You> Check my balance after delegation
You> Show all recent transactions
```

### Concurrent Operations Test

```bash
# Terminal 1
p2engine chat with agent_alpha
You> Transfer 50 to agent_beta

# Terminal 2 (simultaneously)
p2engine chat with agent_beta
You> Transfer 30 to agent_alpha
```

### Comprehensive Rollout Test

```bash
# Run all example rollouts
p2engine rollout start config/demo_rollout.yml
p2engine rollout start config/rollout_task_with_payment.yml
p2engine rollout start config/rollout_competitive_payment.yml
p2engine rollout start config/rollout_hierarchical_distribution.yml

# Check results
p2engine ledger overview
p2engine ledger audit
```

## üìö Key Concepts

### Interaction Stack

Each agent maintains a stack of interaction states (messages, tool calls, results) that can be branched and rewound.

### Effects System

Actions that modify external state (tool calls, delegations) are managed through an effects system with proper isolation and retry logic.

### Artifact Bus

All significant events and data are stored as artifacts with full provenance tracking.

### Deduplication Policies

- **none**: No deduplication
- **penalty**: Track duplicates but allow execution
- **strict**: Block duplicate side-effect operations

## üîç Troubleshooting

### Canton Connection Issues

```bash
# Check Canton health
./scripts/canton-health-check.sh

# Debug ledger connection
p2engine ledger debug

# Restart Canton services
pkill -f canton
./scripts/start_canton.sh
```

### Redis Connection

```bash
# Check Redis
redis-cli ping

# Clear Redis (development only!)
redis-cli FLUSHDB
```

### View Logs

```bash
# Main log
tail -f logs/main.log

# Celery worker logs
tail -f logs/run_*/workers/*.log

# Canton logs
tail -f logs/canton/*.log
```

## üìÑ Access & Rights

**This is a closed academic work for a Master's thesis.**

- **Access Period**: Sensors (examiners) may view and test the code only during the official examination period
- **Restrictions**: After the examination period, all access must be revoked
- **Intellectual Property**: The ideas, concepts, and implementations in this work may not be reshared or redistributed
- **Authorized Users**: Limited to the thesis supervisor, student, and designated sensors/examiners

## üõ†Ô∏è Technology Stack

### Core Framework

- **[LiteLLM](https://github.com/BerriAI/litellm)** - Unified interface for multiple LLM providers
- **[Celery](https://docs.celeryproject.org/)** - Distributed task queue for scalable execution
- **[Redis](https://redis.io/)** - In-memory data store for caching and message passing

### Ledger Technology

- **[Canton](https://www.digitalasset.com/developers)** - Distributed ledger infrastructure
- **[Daml](https://daml.com/)** - Smart contract language for ledger transactions

### Development Tools

- **[Poetry](https://python-poetry.org/)** - Dependency management and packaging
- **[Typer](https://typer.tiangolo.com/)** - CLI interface framework
- **[Rich](https://github.com/Textualize/rich)** - Terminal formatting and UI components
- **[Pydantic](https://pydantic-docs.helpmanual.io/)** - Data validation and settings management

### AI/ML Infrastructure

- **[OpenAI API](https://openai.com/api/)** - Primary LLM provider
- **[Jinja2](https://jinja.palletsprojects.com/)** - Template engine for prompt engineering
- **[JSONSchema](https://json-schema.org/)** - Tool parameter validation

---

<div align="center">
<strong>Master's Thesis Project</strong><br>
<em>Multi-Agent Orchestration with Financial Ledger Integration</em><br>
<br>
¬© 2024 - Academic Use Only
</div>
